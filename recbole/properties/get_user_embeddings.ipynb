{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from recbole.quick_start import load_data_and_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marta/jku/RecBole/recbole/properties'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The onion dataset used for training the model should be stored as \n",
    "\n",
    "```python\n",
    "os.getcwd() + /dataset/onion/onion.inter\n",
    "```\n",
    "\n",
    "In this case `'/home/marta/jku/RecBole/recbole/properties/dataset/onion/onion.inter'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['onion_timestamp_thresh.inter', 'onion_binarized_thresh.inter', 'onion.inter']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(os.getcwd() + '/dataset/onion')\n",
    "# The third file is the one that MUST be there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best model has hyperparams:\n",
    "\n",
    "```python\n",
    "anneal_cap:1.0, latent_dimension:1000, learning_rate:0.001, mlp_hidden_size:[], total_anneal_steps:5000.0\n",
    "Valid result:\n",
    "recall@10 : 0.461    mrr@10 : 0.6899    ndcg@10 : 0.4949    hit@10 : 0.7519    precision@10 : 0.1979\n",
    "Test result:\n",
    "recall@10 : 0.4594    mrr@10 : 0.685    ndcg@10 : 0.4955    hit@10 : 0.7424    precision@10 : 0.196\n",
    "```\n",
    "\n",
    "The variable `model_path` is the path to where the model is stored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = '/home/marta/jku/RecBole/saved/MultiVAE-Dec-05-2022_17-02-47.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this command only once, not every time you get the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06 Dec 15:31    INFO  \n",
      "General Hyper Parameters:\n",
      "gpu_id = 0\n",
      "use_gpu = True\n",
      "seed = 2020\n",
      "state = INFO\n",
      "reproducibility = True\n",
      "data_path = dataset/onion\n",
      "checkpoint_dir = saved\n",
      "show_progress = True\n",
      "save_dataset = False\n",
      "dataset_save_path = None\n",
      "save_dataloaders = False\n",
      "dataloaders_save_path = None\n",
      "log_wandb = True\n",
      "\n",
      "Training Hyper Parameters:\n",
      "epochs = 300\n",
      "train_batch_size = 2048\n",
      "learner = adam\n",
      "learning_rate = 0.001\n",
      "train_neg_sample_args = {'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}\n",
      "eval_step = 1\n",
      "stopping_step = 10\n",
      "clip_grad_norm = None\n",
      "weight_decay = 0.0\n",
      "loss_decimal_place = 4\n",
      "\n",
      "Evaluation Hyper Parameters:\n",
      "eval_args = {'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}\n",
      "repeatable = False\n",
      "metrics = ['Recall', 'MRR', 'NDCG', 'Hit', 'Precision']\n",
      "topk = [10]\n",
      "valid_metric = MRR@10\n",
      "valid_metric_bigger = True\n",
      "eval_batch_size = 4096\n",
      "metric_decimal_place = 4\n",
      "\n",
      "Dataset Hyper Parameters:\n",
      "field_separator = \t\n",
      "seq_separator =  \n",
      "USER_ID_FIELD = user_id\n",
      "ITEM_ID_FIELD = item_id\n",
      "RATING_FIELD = rating\n",
      "TIME_FIELD = timestamp\n",
      "seq_len = None\n",
      "LABEL_FIELD = label\n",
      "threshold = None\n",
      "NEG_PREFIX = neg_\n",
      "load_col = {'inter': ['user_id', 'item_id']}\n",
      "unload_col = None\n",
      "unused_col = None\n",
      "additional_feat_suffix = None\n",
      "rm_dup_inter = None\n",
      "val_interval = None\n",
      "filter_inter_by_user_or_item = True\n",
      "user_inter_num_interval = [0,inf)\n",
      "item_inter_num_interval = [0,inf)\n",
      "alias_of_user_id = None\n",
      "alias_of_item_id = None\n",
      "alias_of_entity_id = None\n",
      "alias_of_relation_id = None\n",
      "preload_weight = None\n",
      "normalize_field = None\n",
      "normalize_all = None\n",
      "ITEM_LIST_LENGTH_FIELD = item_length\n",
      "LIST_SUFFIX = _list\n",
      "MAX_ITEM_LIST_LENGTH = 50\n",
      "POSITION_FIELD = position_id\n",
      "HEAD_ENTITY_ID_FIELD = head_id\n",
      "TAIL_ENTITY_ID_FIELD = tail_id\n",
      "RELATION_ID_FIELD = relation_id\n",
      "ENTITY_ID_FIELD = entity_id\n",
      "benchmark_filename = None\n",
      "\n",
      "Other Hyper Parameters: \n",
      "worker = 0\n",
      "wandb_project = relistening_behaviour\n",
      "shuffle = True\n",
      "require_pow = False\n",
      "enable_amp = False\n",
      "enable_scaler = False\n",
      "transform = None\n",
      "mlp_hidden_size = []\n",
      "latent_dimension = 1000\n",
      "dropout_prob = 0.5\n",
      "anneal_cap = 1.0\n",
      "total_anneal_steps = 5000.0\n",
      "numerical_features = []\n",
      "discretization = None\n",
      "kg_reverse_r = False\n",
      "entity_kg_num_interval = [0,inf)\n",
      "relation_kg_num_interval = [0,inf)\n",
      "MODEL_TYPE = ModelType.GENERAL\n",
      "params_file = /home/marta/jku/fairinterplay/config/vae_params.yaml\n",
      "output_file = ./vae_ml_out.yaml\n",
      "tool = Hyperopt\n",
      "MODEL_INPUT_TYPE = InputType.PAIRWISE\n",
      "eval_type = EvaluatorType.RANKING\n",
      "single_spec = True\n",
      "local_rank = 0\n",
      "device = cuda\n",
      "eval_neg_sample_args = {'distribution': 'uniform', 'sample_num': 'none'}\n",
      "\n",
      "\n",
      "06 Dec 15:31    INFO  onion\n",
      "The number of users: 14325\n",
      "Average actions of users: 47.10262496509355\n",
      "The number of items: 21610\n",
      "Average actions of items: 31.223008931463742\n",
      "The number of inters: 674698\n",
      "The sparsity of the dataset: 99.78204841821501%\n",
      "Remain Fields: ['user_id', 'item_id']\n",
      "06 Dec 15:31    INFO  [Training]: train_batch_size = [2048] train_neg_sample_args: [{'distribution': 'uniform', 'sample_num': 1, 'alpha': 1.0, 'dynamic': False, 'candidate_num': 0}]\n",
      "06 Dec 15:31    INFO  [Evaluation]: eval_batch_size = [4096] eval_args: [{'split': {'RS': [0.8, 0.1, 0.1]}, 'group_by': 'user', 'order': 'RO', 'mode': 'full'}]\n"
     ]
    }
   ],
   "source": [
    "config, model, dataset, _, _, test_data = load_data_and_model(\n",
    "    model_file=model_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_embeddings(model, rating_matrix, device='cpu'):\n",
    "    \"\"\"\n",
    "    the embedding of all users as a matrix\n",
    "    of dimensions rating_matrix_users x self.lat_dim / 2.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model = model.cpu()\n",
    "    rating_matrix = torch.from_numpy(rating_matrix).float().to('cpu')\n",
    "    h = F.normalize(rating_matrix)\n",
    "    h = model.encoder(h).detach()\n",
    "    mu = h[:, : int(model.lat_dim / 2)]\n",
    "    return mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, every time you want to get the embeddings for ALL users, run the command:\n",
    "```python\n",
    "get_users_embeddings(model, ratings)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE\n",
    "To show how to use this, I randomly initialize a numpy array which mimics the ratings of all users, with values between 0 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_users_to_embed = model.n_users\n",
    "\n",
    "random_ratings = np.random.randint(\n",
    "    low=0,\n",
    "    high=5,\n",
    "    size=(number_of_users_to_embed, model.n_items),\n",
    "    )\n",
    "\n",
    "ratings = ratings.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.55 s, sys: 436 ms, total: 4.98 s\n",
      "Wall time: 4.98 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2680,  1.4486, -1.3804,  ..., -2.3318, -1.7511,  2.3152],\n",
       "        [-1.1380,  1.3699, -1.3971,  ..., -2.2866, -1.8190,  2.3561],\n",
       "        [-1.0934,  1.1066, -1.2829,  ..., -2.3980, -1.7706,  2.2853],\n",
       "        ...,\n",
       "        [-1.1269,  1.2225, -1.4497,  ..., -2.3581, -1.8424,  2.3597],\n",
       "        [-1.2089,  1.3597, -1.5738,  ..., -2.3124, -1.8852,  2.4201],\n",
       "        [-1.1323,  1.2751, -1.5294,  ..., -2.4074, -1.8562,  2.4560]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "embeddings = get_users_embeddings(model, random_ratings)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the embeddings takes roughly 5 seconds.\n",
    "\n",
    "If needed, you can convert the embeddings to a numpy array: (or call any other method of the class `torch` from `PyTorch`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2679526,  1.4485517, -1.3804485, ..., -2.3318236, -1.7511073,\n",
       "         2.3152251],\n",
       "       [-1.1379719,  1.3698629, -1.3970743, ..., -2.2865617, -1.8190303,\n",
       "         2.3561013],\n",
       "       [-1.0934396,  1.1066333, -1.2828555, ..., -2.3980165, -1.7706003,\n",
       "         2.2853076],\n",
       "       ...,\n",
       "       [-1.1268995,  1.2225186, -1.4496777, ..., -2.3580883, -1.8424143,\n",
       "         2.3596866],\n",
       "       [-1.2089083,  1.3596578, -1.5738242, ..., -2.3124287, -1.8851516,\n",
       "         2.420097 ],\n",
       "       [-1.1323131,  1.2750775, -1.5293826, ..., -2.4073868, -1.8561652,\n",
       "         2.4559958]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = embeddings.numpy()\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is (number of users + 1, embedding dimension) because user 0 is an artifact of RecBole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14325, 500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/home/marta/jku/RecBole/saved/BPR-Dec-05-2022_16-16-44.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.get_user_embedding(torch.from_numpy(np.arange(model.n_users))).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['[PAD]', '51918', '70143', ..., '32569', '86959', '21778'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.id2token(dataset.uid_field, np.arange(model.n_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr_embeddings = pd.DataFrame(embeddings)\n",
    "bpr_embeddings['user_id'] = dataset.id2token(dataset.uid_field, np.arange(model.n_users))\n",
    "bpr_embeddings = bpr_embeddings.set_index('user_id')\n",
    "bpr_embeddings.head()\n",
    "bpr_embeddings.to_csv('BPR_embeddings.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
